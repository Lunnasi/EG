git clone https://github.com/Lunnasi/EG.git --branch EG/home_work

Multi-node cluster install

1. Download and intall JAva and Hadoop on all the systems
2. Specify the IP address of each system followed by their host names in host file of each system
3. COnfigure hadoop configuration files (core-site,hdfs-site,mapred-site,yasrn-site)
4. Edit slaves file on master node
5. Format namenode and start all hadoop services
6. Check live nodes on Hadoop namenode UI
   hdfs dfsadmin report 

Deploy server:
EGHome  -  192.168.56.105

Master Deamons will run on
hadoop  -  192.168.56.11
HDFS - Name node
YARN - Resource Manager

Slave Deamons will run on
nn1  -  192.168.56.12
nn2  -  192.168.56.13
HDFS - Data node
YARN - Node manager

host_file:
192.168.56.11 hadoop hadoop.cluster2.com
192.168.56.12 dn1 dn1.cluster2.com
192.168.56.13 dn2 dn2.cluster2.com
192.168.56.105 eghome eg.cluster2.com

Property Files

core-site.xml
-------------------------------------------
<property>
  <name>fs.default.FS</name>
  <value>hdfs://192.168.56.105:8020</value>
</property>

hdfs-site.xml
--------------------------------------------
<property>
  <name>dfs.namenode.name.dir</name>
  <value>file:</value>
</property>

<property>
  <name>dfs.datanode.name.dir</name>
  <value>file:</value>
</property>

mapred-site.xml
----------------------------------------------
<property>

</property>



ssh-keygen -t rsa -C "example@gmail.com"

cd /vagrant/
cp /home/vagrant/.ssh/id_rsa.pub .


readlink -f /usr/bin/java | sed "s:bin/java::"

lineinfile: dest="{{ hadoop_home }}/etc/hadoop/hadoop-env.sh" regexp=JAVA_HOME= line="export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64"

/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep ~/input ~/grep_example 'principal[.]*'
ls -s hadoop-3.1.2 hadoop

ls -l core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml
hdf dfs -ls
